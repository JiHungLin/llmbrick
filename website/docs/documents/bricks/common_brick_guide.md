# CommonBrick

æœ¬æŒ‡å—è©³ç´°èªªæ˜ [`llmbrick/bricks/common/common.py`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/bricks/common/common.py) ä¸­çš„ CommonBrick å¯¦ä½œï¼Œé€™æ˜¯ LLMBrick æ¡†æ¶ä¸­æœ€åŸºç¤ä¸”é‡è¦çš„çµ„ä»¶ã€‚

---

## å°ˆæ¡ˆæ¦‚è¿°èˆ‡ç›®æ¨™

### ğŸ¯ è¨­è¨ˆç›®æ¨™èˆ‡è§£æ±ºå•é¡Œ

CommonBrick æ˜¯ LLMBrick æ¡†æ¶çš„æ ¸å¿ƒåŸºç¤çµ„ä»¶ï¼Œè¨­è¨ˆç”¨ä¾†è§£æ±ºä»¥ä¸‹é—œéµå•é¡Œï¼š

- **çµ±ä¸€ä»‹é¢å”å®š**ï¼šç‚ºæ‰€æœ‰ Brick é¡å‹æä¾›æ¨™æº–åŒ–çš„è«‹æ±‚/å›æ‡‰è™•ç†æ©Ÿåˆ¶
- **å¤šå”å®šæ”¯æ´**ï¼šå…§å»ºå®Œæ•´çš„ gRPC æœå‹™æ”¯æ´ï¼Œæ”¯æ´å››ç¨®é€šè¨Šæ¨¡å¼
- **æ“´å±•åŸºç¤**ï¼šä½œç‚ºå…¶ä»–å°ˆç”¨ Brickï¼ˆLLMBrickã€GuardBrick ç­‰ï¼‰çš„ç¹¼æ‰¿åŸºç¤
- **æœå‹™åŒ–èƒ½åŠ›**ï¼šå¯è¼•é¬†è½‰æ›ç‚ºç¨ç«‹çš„å¾®æœå‹™æˆ–å®¢æˆ¶ç«¯
- **éŒ¯èª¤è™•ç†æ¨™æº–åŒ–**ï¼šæä¾›çµ±ä¸€çš„éŒ¯èª¤è™•ç†å’Œç‹€æ…‹ç®¡ç†æ©Ÿåˆ¶

### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½ç‰¹è‰²

- **å››ç¨®é€šè¨Šæ¨¡å¼**ï¼šUnaryï¼ˆå–®æ¬¡ï¼‰ã€Input Streamingï¼ˆè¼¸å…¥ä¸²æµï¼‰ã€Output Streamingï¼ˆè¼¸å‡ºä¸²æµï¼‰ã€Bidirectional Streamingï¼ˆé›™å‘ä¸²æµï¼‰
- **è£é£¾å™¨æ¨¡å¼**ï¼šæ”¯æ´å‹•æ…‹è¨»å†Šè™•ç†å™¨ï¼Œéˆæ´»çµ„åˆæ¥­å‹™é‚è¼¯
- **é¡åˆ¥ç¹¼æ‰¿æ¨¡å¼**ï¼šæ”¯æ´å‚³çµ±çš„é¡åˆ¥ç¹¼æ‰¿æ–¹å¼å®šç¾©è™•ç†å™¨
- **è‡ªå‹• gRPC è½‰æ›**ï¼šä¸€éµè½‰æ›ç‚º gRPC å®¢æˆ¶ç«¯æˆ–æœå‹™ç«¯
- **å®Œæ•´éŒ¯èª¤è™•ç†**ï¼šå…§å»ºè±å¯Œçš„éŒ¯èª¤ç¢¼å’ŒéŒ¯èª¤è™•ç†æ©Ÿåˆ¶

---

## å°ˆæ¡ˆçµæ§‹åœ–èˆ‡æ¨¡çµ„è©³è§£

### æ•´é«”æ¶æ§‹åœ–

```plaintext
LLMBrick Framework
â”œâ”€â”€ llmbrick/
â”‚   â”œâ”€â”€ core/                           # æ ¸å¿ƒåŸºç¤æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ brick.py                    # BaseBrick åŸºç¤é¡åˆ¥èˆ‡è£é£¾å™¨
â”‚   â”‚   â”œâ”€â”€ error_codes.py              # çµ±ä¸€éŒ¯èª¤ç¢¼å®šç¾©
â”‚   â”‚   â””â”€â”€ exceptions.py               # è‡ªè¨‚ä¾‹å¤–é¡åˆ¥
â”‚   â”‚
â”‚   â”œâ”€â”€ bricks/                         # Brick å¯¦ä½œæ¨¡çµ„
â”‚   â”‚   â””â”€â”€ common/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ common.py               # CommonBrick ä¸»é«”å¯¦ä½œ
â”‚   â”‚
â”‚   â”œâ”€â”€ protocols/                      # å”å®šå®šç¾©æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ grpc/                       # gRPC å”å®š
â”‚   â”‚   â”‚   â””â”€â”€ common/
â”‚   â”‚   â”‚       â”œâ”€â”€ common.proto        # Protocol Buffer å®šç¾©
â”‚   â”‚   â”‚       â”œâ”€â”€ common_pb2.py       # è‡ªå‹•ç”Ÿæˆçš„è¨Šæ¯é¡åˆ¥
â”‚   â”‚   â”‚       â””â”€â”€ common_pb2_grpc.py  # è‡ªå‹•ç”Ÿæˆçš„æœå‹™å­˜æ ¹
â”‚   â”‚   â””â”€â”€ models/                     # è³‡æ–™æ¨¡å‹
â”‚   â”‚       â””â”€â”€ bricks/
â”‚   â”‚           â””â”€â”€ common_types.py     # CommonBrick è³‡æ–™é¡å‹
â”‚   â”‚
â”‚   â””â”€â”€ servers/                        # æœå‹™å™¨å¯¦ä½œ
â”‚       â””â”€â”€ grpc/
â”‚           â”œâ”€â”€ server.py               # gRPC æœå‹™å™¨
â”‚           â””â”€â”€ wrappers/
â”‚               â””â”€â”€ common_grpc_wrapper.py  # CommonBrick gRPC åŒ…è£å™¨
```

### æ ¸å¿ƒæ¨¡çµ„è©³ç´°èªªæ˜

#### 1. [`BaseBrick`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L71) - åŸºç¤æŠ½è±¡é¡åˆ¥

**è·è²¬**ï¼šæ‰€æœ‰ Brick çš„åŸºç¤é¡åˆ¥ï¼Œå®šç¾©æ¨™æº–ä»‹é¢å’Œè¡Œç‚º

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- **æ³›å‹æ”¯æ´**ï¼š`BaseBrick[InputT, OutputT]` æä¾›å‹åˆ¥å®‰å…¨
- **è™•ç†å™¨ç®¡ç†**ï¼šè‡ªå‹•è¨»å†Šå’Œç®¡ç†äº”ç¨®è™•ç†å™¨é¡å‹
- **è£é£¾å™¨æ”¯æ´**ï¼šæä¾› `@brick.unary()` ç­‰è£é£¾å™¨æ–¹æ³•
- **åŸ·è¡Œå…¥å£**ï¼šæä¾› `run_*` ç³»åˆ—æ–¹æ³•ä½œç‚ºçµ±ä¸€åŸ·è¡Œå…¥å£
- **éŒ¯èª¤è™•ç†**ï¼šå…§å»ºç•°å¸¸æ•ç²å’Œæ—¥èªŒè¨˜éŒ„

**é—œéµå±¬æ€§**ï¼š
```python
class BaseBrick(Generic[InputT, OutputT]):
    brick_type: Optional[BrickType] = None              # Brick é¡å‹æ¨™è­˜
    allowed_handler_types: Optional[set] = None         # å…è¨±çš„è™•ç†å™¨é¡å‹é™åˆ¶
    _unary_handler: Optional[UnaryHandler] = None       # å–®æ¬¡è«‹æ±‚è™•ç†å™¨
    _output_streaming_handler: Optional[...] = None     # è¼¸å‡ºä¸²æµè™•ç†å™¨
    _input_streaming_handler: Optional[...] = None      # è¼¸å…¥ä¸²æµè™•ç†å™¨
    _bidi_streaming_handler: Optional[...] = None       # é›™å‘ä¸²æµè™•ç†å™¨
    _get_service_info_handler: Optional[...] = None     # æœå‹™è³‡è¨Šè™•ç†å™¨
```

#### 2. [`CommonBrick`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/bricks/common/common.py#L15) - é€šç”¨ Brick å¯¦ä½œ

**è·è²¬**ï¼šæä¾›é€šç”¨çš„è«‹æ±‚/å›æ‡‰è™•ç†èƒ½åŠ›ï¼Œæ”¯æ´æ‰€æœ‰é€šè¨Šæ¨¡å¼

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- **ç¹¼æ‰¿ BaseBrick**ï¼šç²å¾—å®Œæ•´çš„åŸºç¤åŠŸèƒ½
- **gRPC æ•´åˆ**ï¼šå…§å»º `toGrpcClient()` æ–¹æ³•
- **ç„¡é™åˆ¶è™•ç†å™¨**ï¼šæ”¯æ´æ‰€æœ‰äº”ç¨®è™•ç†å™¨é¡å‹
- **æ¨™æº–è³‡æ–™æ¨¡å‹**ï¼šä½¿ç”¨ `CommonRequest/CommonResponse`

#### 3. [`ErrorCodes`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/error_codes.py#L12) - éŒ¯èª¤ç¢¼ç®¡ç†

**è·è²¬**ï¼šçµ±ä¸€çš„éŒ¯èª¤ç¢¼å®šç¾©å’Œ ErrorDetail å‰µå»ºå·¥å» 

**éŒ¯èª¤ç¢¼åˆ†é¡**ï¼š
- **HTTP æ¨™æº–ç¢¼**ï¼š200-599ï¼ˆæˆåŠŸã€å®¢æˆ¶ç«¯éŒ¯èª¤ã€æœå‹™å™¨éŒ¯èª¤ï¼‰
- **æ¡†æ¶æ¥­å‹™ç¢¼**ï¼š1000-9999ï¼ˆé€šç”¨ã€é©—è­‰ã€èªè­‰ã€æ¨¡å‹ã€å¤–éƒ¨æœå‹™ã€è³‡æºã€ç¶²è·¯ã€å­˜å„²ã€æ¥­å‹™éŒ¯èª¤ï¼‰

**å·¥å» æ–¹æ³•ç¯„ä¾‹**ï¼š
```python
# å¿«é€Ÿå‰µå»ºå¸¸ç”¨éŒ¯èª¤
ErrorCodes.success()                    # æˆåŠŸç‹€æ…‹
ErrorCodes.parameter_invalid("name")    # åƒæ•¸ç„¡æ•ˆ
ErrorCodes.model_not_found("gpt-4")     # æ¨¡å‹æœªæ‰¾åˆ°
ErrorCodes.internal_error("è©³ç´°éŒ¯èª¤")    # å…§éƒ¨éŒ¯èª¤
```

#### 4. è³‡æ–™æ¨¡å‹ç³»çµ±

**[`CommonRequest`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/protocols/models/bricks/common_types.py#L58)**ï¼š
```python
@dataclass
class CommonRequest:
    data: Dict[str, Any] = field(default_factory=dict)  # éˆæ´»çš„è³‡æ–™è¼‰é«”
```

**[`CommonResponse`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/protocols/models/bricks/common_types.py#L71)**ï¼š
```python
@dataclass
class CommonResponse:
    data: Dict[str, Any] = field(default_factory=dict)  # å›æ‡‰è³‡æ–™
    error: Optional[ErrorDetail] = None                  # éŒ¯èª¤è©³æƒ…
```

**[`ServiceInfoResponse`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/protocols/models/bricks/common_types.py#L106)**ï¼š
```python
@dataclass
class ServiceInfoResponse:
    service_name: str = ""                               # æœå‹™åç¨±
    version: str = ""                                    # ç‰ˆæœ¬è³‡è¨Š
    models: List[ModelInfo] = field(default_factory=list)  # æ”¯æ´çš„æ¨¡å‹
    error: Optional[ErrorDetail] = None                  # éŒ¯èª¤ç‹€æ…‹
```

#### 5. gRPC å”å®šå±¤

**[Protocol Buffer å®šç¾©](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/protocols/grpc/common/common.proto)**ï¼š
```protobuf
service CommonService {
  rpc GetServiceInfo(ServiceInfoRequest) returns (ServiceInfoResponse);
  rpc Unary (CommonRequest) returns (CommonResponse);
  rpc OutputStreaming (CommonRequest) returns (stream CommonResponse);
  rpc InputStreaming (stream CommonRequest) returns (CommonResponse);
  rpc BidiStreaming (stream CommonRequest) returns (stream CommonResponse);
}
```

**[gRPC åŒ…è£å™¨](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/servers/grpc/wrappers/common_grpc_wrapper.py)**ï¼š
- è‡ªå‹•è™•ç† Protocol Buffer èˆ‡ Python ç‰©ä»¶è½‰æ›
- çµ±ä¸€çš„éŒ¯èª¤è™•ç†å’Œç‹€æ…‹ç¢¼æ˜ å°„
- ç•°æ­¥ä¸²æµè™•ç†æ”¯æ´

---

## å®‰è£èˆ‡ç’°å¢ƒè¨­å®šæŒ‡å—

### ä¾è³´éœ€æ±‚

CommonBrick éœ€è¦ä»¥ä¸‹æ ¸å¿ƒä¾è³´ï¼š

```bash
# æ ¸å¿ƒä¾è³´
grpcio>=1.50.0              # gRPC æ ¸å¿ƒåº«
grpcio-tools>=1.50.0        # gRPC å·¥å…·ï¼ˆProtocol Buffer ç·¨è­¯ï¼‰
protobuf>=4.21.0            # Protocol Buffer æ”¯æ´
google-protobuf>=4.21.0     # Google Protocol Buffer æ“´å±•
```

### è‡ªå‹•åŒ–å®‰è£æ­¥é©Ÿ

#### 1. å®‰è£ LLMBrick å¥—ä»¶

```bash
# å¾ PyPI å®‰è£ï¼ˆæ¨è–¦ï¼‰
pip install llmbrick

# æˆ–å¾æºç¢¼å®‰è£
git clone https://github.com/JiHungLin/llmbrick.git
cd llmbrick
pip install -e .
```

#### 2. é©—è­‰å®‰è£

```python
# é©—è­‰å®‰è£æ˜¯å¦æˆåŠŸ
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse

print("âœ… CommonBrick å®‰è£æˆåŠŸï¼")
```

#### 3. é–‹ç™¼ç’°å¢ƒè¨­å®š

```bash
# å®‰è£é–‹ç™¼ä¾è³´
pip install -r requirements-dev.txt

# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆå¯é¸ï¼‰
export LLMBRICK_LOG_LEVEL=INFO
export LLMBRICK_GRPC_PORT=50051
```

---

## é€æ­¥ç¯„ä¾‹ï¼šå¾åŸºç¤åˆ°é€²éš

### 1. æœ€ç°¡å–®çš„ CommonBrick ä½¿ç”¨

```python
import asyncio
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse
from llmbrick.core.error_codes import ErrorCodes

async def basic_example():
    """æœ€åŸºæœ¬çš„ CommonBrick ä½¿ç”¨ç¯„ä¾‹"""
    
    # å»ºç«‹ CommonBrick å¯¦ä¾‹
    brick = CommonBrick()
    
    # ä½¿ç”¨è£é£¾å™¨å®šç¾©è™•ç†é‚è¼¯
    @brick.unary()
    async def echo_handler(request: CommonRequest) -> CommonResponse:
        """ç°¡å–®çš„å›éŸ³è™•ç†å™¨"""
        message = request.data.get("message", "Hello, World!")
        return CommonResponse(
            data={"echo": f"æ”¶åˆ°è¨Šæ¯: {message}"},
            error=ErrorCodes.success()
        )
    
    # åŸ·è¡Œè«‹æ±‚
    request = CommonRequest(data={"message": "æ¸¬è©¦è¨Šæ¯"})
    response = await brick.run_unary(request)
    
    print(f"å›æ‡‰: {response.data}")
    print(f"ç‹€æ…‹: {response.error.message}")

# åŸ·è¡Œç¯„ä¾‹
asyncio.run(basic_example())
```

### 2. é¡åˆ¥ç¹¼æ‰¿æ–¹å¼å®šç¾© CommonBrick

```python
from typing import AsyncIterator
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import (
    CommonRequest, CommonResponse, ErrorDetail, ServiceInfoResponse, ModelInfo
)
from llmbrick.core.error_codes import ErrorCodes
from llmbrick.core.brick import (
    unary_handler, input_streaming_handler, output_streaming_handler, 
    bidi_streaming_handler, get_service_info_handler
)

class TextProcessorBrick(CommonBrick):
    """æ–‡æœ¬è™•ç† Brick ç¯„ä¾‹"""
    
    def __init__(self, processor_name: str = "TextProcessor", **kwargs):
        super().__init__(**kwargs)
        self.processor_name = processor_name
        self.processed_count = 0
    
    @unary_handler
    async def process_text(self, request: CommonRequest) -> CommonResponse:
        """å–®æ¬¡æ–‡æœ¬è™•ç†"""
        try:
            text = request.data.get("text", "")
            if not text:
                return CommonResponse(
                    data={},
                    error=ErrorCodes.parameter_invalid("text", "æ–‡æœ¬å…§å®¹ä¸èƒ½ç‚ºç©º")
                )
            
            # æ¨¡æ“¬æ–‡æœ¬è™•ç†é‚è¼¯
            processed_text = text.upper().strip()
            self.processed_count += 1
            
            return CommonResponse(
                data={
                    "original": text,
                    "processed": processed_text,
                    "length": len(processed_text),
                    "processor": self.processor_name
                },
                error=ErrorCodes.success()
            )
            
        except Exception as e:
            return CommonResponse(
                data={},
                error=ErrorCodes.internal_error(f"è™•ç†å¤±æ•—: {str(e)}")
            )
    
    @output_streaming_handler
    async def stream_process(self, request: CommonRequest) -> AsyncIterator[CommonResponse]:
        """ä¸²æµæ–‡æœ¬è™•ç† - é€å­—è¼¸å‡º"""
        text = request.data.get("text", "")
        if not text:
            yield CommonResponse(
                data={},
                error=ErrorCodes.parameter_invalid("text")
            )
            return
        
        # é€å­—è™•ç†ä¸¦ä¸²æµè¼¸å‡º
        for i, char in enumerate(text):
            await asyncio.sleep(0.1)  # æ¨¡æ“¬è™•ç†å»¶é²
            yield CommonResponse(
                data={
                    "position": i,
                    "character": char,
                    "is_alpha": char.isalpha(),
                    "progress": f"{i+1}/{len(text)}"
                },
                error=ErrorCodes.success()
            )
    
    @input_streaming_handler
    async def batch_process(self, request_stream: AsyncIterator[CommonRequest]) -> CommonResponse:
        """æ‰¹æ¬¡è™•ç†è¼¸å…¥ä¸²æµ"""
        texts = []
        total_length = 0
        
        try:
            async for request in request_stream:
                text = request.data.get("text", "")
                if text:  # å¿½ç•¥ç©ºæ–‡æœ¬
                    texts.append(text)
                    total_length += len(text)
            
            if not texts:
                return CommonResponse(
                    data={},
                    error=ErrorCodes.parameter_invalid("texts", "è‡³å°‘éœ€è¦ä¸€å€‹æœ‰æ•ˆæ–‡æœ¬")
                )
            
            # æ‰¹æ¬¡è™•ç†çµæœ
            processed_texts = [text.upper().strip() for text in texts]
            
            return CommonResponse(
                data={
                    "batch_size": len(texts),
                    "total_length": total_length,
                    "processed_texts": processed_texts,
                    "average_length": total_length / len(texts)
                },
                error=ErrorCodes.success()
            )
            
        except Exception as e:
            return CommonResponse(
                data={},
                error=ErrorCodes.internal_error(f"æ‰¹æ¬¡è™•ç†å¤±æ•—: {str(e)}")
            )
    
    @bidi_streaming_handler
    async def interactive_process(self, request_stream: AsyncIterator[CommonRequest]) -> AsyncIterator[CommonResponse]:
        """é›™å‘ä¸²æµäº’å‹•è™•ç†"""
        session_id = f"session_{asyncio.get_event_loop().time()}"
        message_count = 0
        
        try:
            async for request in request_stream:
                message_count += 1
                text = request.data.get("text", "")
                
                if not text:
                    yield CommonResponse(
                        data={"session_id": session_id, "message_count": message_count},
                        error=ErrorCodes.parameter_invalid("text", "æ–‡æœ¬ä¸èƒ½ç‚ºç©º")
                    )
                    continue
                
                # äº’å‹•å¼è™•ç†é‚è¼¯
                if text.lower() == "exit":
                    yield CommonResponse(
                        data={
                            "session_id": session_id,
                            "message": "æœƒè©±çµæŸ",
                            "total_messages": message_count
                        },
                        error=ErrorCodes.success()
                    )
                    break
                
                # è™•ç†ä¸¦å›æ‡‰
                processed = text.upper()
                yield CommonResponse(
                    data={
                        "session_id": session_id,
                        "message_count": message_count,
                        "original": text,
                        "processed": processed,
                        "timestamp": asyncio.get_event_loop().time()
                    },
                    error=ErrorCodes.success()
                )
                
        except Exception as e:
            yield CommonResponse(
                data={"session_id": session_id},
                error=ErrorCodes.internal_error(f"äº’å‹•è™•ç†å¤±æ•—: {str(e)}")
            )
    
    @get_service_info_handler
    async def get_service_info(self) -> ServiceInfoResponse:
        """æœå‹™è³‡è¨ŠæŸ¥è©¢"""
        return ServiceInfoResponse(
            service_name=f"{self.processor_name}Service",
            version="1.0.0",
            models=[
                ModelInfo(
                    model_id="text_processor_v1",
                    version="1.0.0",
                    supported_languages=["zh", "en"],
                    support_streaming=True,
                    description="é€šç”¨æ–‡æœ¬è™•ç†æ¨¡å‹ï¼Œæ”¯æ´å¤§å°å¯«è½‰æ›ã€é•·åº¦çµ±è¨ˆç­‰åŠŸèƒ½"
                )
            ],
            error=ErrorCodes.success()
        )

# ä½¿ç”¨ç¯„ä¾‹
async def advanced_example():
    """é€²éšä½¿ç”¨ç¯„ä¾‹"""
    brick = TextProcessorBrick("AdvancedProcessor")
    
    # æ¸¬è©¦å–®æ¬¡è™•ç†
    print("=== å–®æ¬¡è™•ç†æ¸¬è©¦ ===")
    request = CommonRequest(data={"text": "hello world"})
    response = await brick.run_unary(request)
    print(f"è™•ç†çµæœ: {response.data}")
    
    # æ¸¬è©¦ä¸²æµè¼¸å‡º
    print("\n=== ä¸²æµè¼¸å‡ºæ¸¬è©¦ ===")
    request = CommonRequest(data={"text": "ABC"})
    async for response in brick.run_output_streaming(request):
        print(f"å­—ç¬¦: {response.data}")
    
    # æ¸¬è©¦æœå‹™è³‡è¨Š
    print("\n=== æœå‹™è³‡è¨Š ===")
    info = await brick.run_get_service_info()
    print(f"æœå‹™: {info.service_name}, ç‰ˆæœ¬: {info.version}")
    print(f"æ¨¡å‹: {info.models[0].model_id}")

asyncio.run(advanced_example())
```

### 3. gRPC æœå‹™ç«¯å»ºç«‹èˆ‡éƒ¨ç½²

```python
# grpc_server.py
import asyncio
from llmbrick.servers.grpc.server import GrpcServer
from text_processor_brick import TextProcessorBrick

async def start_grpc_server():
    """å•Ÿå‹• gRPC æœå‹™ç«¯"""
    
    # å»ºç«‹ gRPC æœå‹™å™¨
    server = GrpcServer(
        port=50051,
        max_workers=10,
        options=[
            ('grpc.keepalive_time_ms', 30000),
            ('grpc.keepalive_timeout_ms', 5000),
            ('grpc.keepalive_permit_without_calls', True),
            ('grpc.http2.max_pings_without_data', 0),
            ('grpc.http2.min_time_between_pings_ms', 10000),
            ('grpc.http2.min_ping_interval_without_data_ms', 300000)
        ]
    )
    
    # å»ºç«‹ä¸¦è¨»å†Š Brick æœå‹™
    text_processor = TextProcessorBrick(
        processor_name="ProductionTextProcessor",
        verbose=True  # å•Ÿç”¨è©³ç´°æ—¥èªŒ
    )
    
    server.register_service(text_processor)
    
    print("ğŸš€ gRPC æœå‹™å™¨å•Ÿå‹•ä¸­...")
    print(f"ğŸ“¡ ç›£è½åœ°å€: localhost:50051")
    print(f"ğŸ”§ æœå‹™åç¨±: {text_processor.processor_name}")
    
    try:
        await server.start()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æœå‹™å™¨é—œé–‰ä¸­...")
        await server.stop()

if __name__ == "__main__":
    asyncio.run(start_grpc_server())
```

### 4. gRPC å®¢æˆ¶ç«¯é€£æ¥èˆ‡ä½¿ç”¨

```python
# grpc_client.py
import asyncio
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest

async def grpc_client_example():
    """gRPC å®¢æˆ¶ç«¯ä½¿ç”¨ç¯„ä¾‹"""
    
    # å»ºç«‹ gRPC å®¢æˆ¶ç«¯
    client = CommonBrick.toGrpcClient("localhost:50051")
    
    print("ğŸ”— é€£æ¥åˆ° gRPC æœå‹™å™¨...")
    
    try:
        # 1. æŸ¥è©¢æœå‹™è³‡è¨Š
        print("\n=== æœå‹™è³‡è¨ŠæŸ¥è©¢ ===")
        service_info = await client.run_get_service_info()
        print(f"æœå‹™åç¨±: {service_info.service_name}")
        print(f"ç‰ˆæœ¬: {service_info.version}")
        if service_info.models:
            model = service_info.models[0]
            print(f"æ¨¡å‹: {model.model_id} (v{model.version})")
            print(f"æ”¯æ´èªè¨€: {', '.join(model.supported_languages)}")
            print(f"æ”¯æ´ä¸²æµ: {'æ˜¯' if model.support_streaming else 'å¦'}")
        
        # 2. å–®æ¬¡è«‹æ±‚æ¸¬è©¦
        print("\n=== å–®æ¬¡è«‹æ±‚æ¸¬è©¦ ===")
        request = CommonRequest(data={"text": "hello grpc world"})
        response = await client.run_unary(request)
        
        if response.error.code == 200:
            print(f"âœ… è™•ç†æˆåŠŸ")
            print(f"åŸæ–‡: {response.data['original']}")
            print(f"è™•ç†å¾Œ: {response.data['processed']}")
            print(f"é•·åº¦: {response.data['length']}")
        else:
            print(f"âŒ è™•ç†å¤±æ•—: {response.error.message}")
        
        # 3. ä¸²æµè¼¸å‡ºæ¸¬è©¦
        print("\n=== ä¸²æµè¼¸å‡ºæ¸¬è©¦ ===")
        request = CommonRequest(data={"text": "Stream"})
        print("ä¸²æµè™•ç†ä¸­...")
        
        async for response in client.run_output_streaming(request):
            if response.error.code == 200:
                data = response.data
                print(f"ä½ç½® {data['position']}: '{data['character']}' "
                      f"({'å­—æ¯' if data['is_alpha'] else 'éå­—æ¯'}) "
                      f"é€²åº¦: {data['progress']}")
            else:
                print(f"âŒ ä¸²æµéŒ¯èª¤: {response.error.message}")
                break
        
        # 4. è¼¸å…¥ä¸²æµæ¸¬è©¦
        print("\n=== è¼¸å…¥ä¸²æµæ¸¬è©¦ ===")
        
        async def input_generator():
            """ç”Ÿæˆè¼¸å…¥ä¸²æµ"""
            texts = ["Hello", "gRPC", "Streaming", "World"]
            for text in texts:
                print(f"ğŸ“¤ ç™¼é€: {text}")
                yield CommonRequest(data={"text": text})
                await asyncio.sleep(0.5)
        
        response = await client.run_input_streaming(input_generator())
        if response.error.code == 200:
            print(f"âœ… æ‰¹æ¬¡è™•ç†å®Œæˆ")
            print(f"è™•ç†æ•¸é‡: {response.data['batch_size']}")
            print(f"ç¸½é•·åº¦: {response.data['total_length']}")
            print(f"å¹³å‡é•·åº¦: {response.data['average_length']:.2f}")
        else:
            print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {response.error.message}")
        
        # 5. é›™å‘ä¸²æµæ¸¬è©¦
        print("\n=== é›™å‘ä¸²æµæ¸¬è©¦ ===")
        
        async def bidi_input_generator():
            """ç”Ÿæˆé›™å‘ä¸²æµè¼¸å…¥"""
            messages = ["hello", "how are you", "grpc is great", "exit"]
            for msg in messages:
                print(f"ğŸ“¤ ç™¼é€: {msg}")
                yield CommonRequest(data={"text": msg})
                await asyncio.sleep(1)
        
        print("é›™å‘ä¸²æµé€šè¨Šä¸­...")
        async for response in client.run_bidi_streaming(bidi_input_generator()):
            if response.error.code == 200:
                data = response.data
                if "message" in data:  # çµæŸè¨Šæ¯
                    print(f"ğŸ {data['message']}, ç¸½è¨Šæ¯æ•¸: {data['total_messages']}")
                else:  # æ­£å¸¸è™•ç†è¨Šæ¯
                    print(f"ğŸ“¥ æ”¶åˆ°å›æ‡‰ #{data['message_count']}: "
                          f"'{data['original']}' -> '{data['processed']}'")
            else:
                print(f"âŒ é›™å‘ä¸²æµéŒ¯èª¤: {response.error.message}")
                break
    
    except Exception as e:
        print(f"âŒ å®¢æˆ¶ç«¯éŒ¯èª¤: {str(e)}")
    
    print("\nğŸ”š å®¢æˆ¶ç«¯æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(grpc_client_example())
```

---

## æ ¸å¿ƒ API / é¡åˆ¥ / å‡½å¼æ·±åº¦è§£æ

### [`CommonBrick`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/bricks/common/common.py#L15) é¡åˆ¥

#### é¡åˆ¥ç°½åèˆ‡ç¹¼æ‰¿é—œä¿‚

```python
class CommonBrick(BaseBrick[CommonRequest, CommonResponse]):
    """
    CommonBrick: åŸºæ–¼ BaseBrick çš„é€šç”¨æœå‹™
    
    æ³›å‹åƒæ•¸:
        InputT: CommonRequest - è¼¸å…¥è«‹æ±‚é¡å‹
        OutputT: CommonResponse - è¼¸å‡ºå›æ‡‰é¡å‹
    """
    brick_type = BrickType.COMMON  # æ¨™è­˜ç‚º COMMON é¡å‹ Brick
```

#### æ ¸å¿ƒæ–¹æ³•è©³è§£

##### [`toGrpcClient()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/bricks/common/common.py#L37) - gRPC å®¢æˆ¶ç«¯è½‰æ›

```python
@classmethod
def toGrpcClient(cls, remote_address: str, **kwargs) -> CommonBrick
```

**åŠŸèƒ½**ï¼šå°‡ CommonBrick è½‰æ›ç‚ºç•°æ­¥ gRPC å®¢æˆ¶ç«¯

**åƒæ•¸è©³è§£**ï¼š
- `remote_address: str` - gRPC ä¼ºæœå™¨åœ°å€
  - æ ¼å¼ï¼š`"host:port"`ï¼ˆå¦‚ `"localhost:50051"`ï¼‰
  - æ”¯æ´ IPv4/IPv6 åœ°å€
  - æ”¯æ´åŸŸåè§£æ
- `**kwargs` - å‚³éçµ¦ CommonBrick å»ºæ§‹å­çš„é¡å¤–åƒæ•¸
  - `verbose: bool = True` - æ˜¯å¦å•Ÿç”¨è©³ç´°æ—¥èªŒ
  - å…¶ä»–è‡ªè¨‚åˆå§‹åŒ–åƒæ•¸

**å›å‚³å€¼**ï¼šé…ç½®ç‚º gRPC å®¢æˆ¶ç«¯çš„ CommonBrick å¯¦ä¾‹

**å…§éƒ¨å¯¦ä½œåŸç†**ï¼š
1. å»ºç«‹ CommonBrick å¯¦ä¾‹
2. ç‚ºæ¯ç¨®é€šè¨Šæ¨¡å¼å‹•æ…‹è¨»å†Š gRPC è™•ç†å™¨
3. æ¯å€‹è™•ç†å™¨å…§éƒ¨å»ºç«‹ gRPC é€šé“å’Œå®¢æˆ¶ç«¯å­˜æ ¹
4. è‡ªå‹•è™•ç† Protocol Buffer èˆ‡ Python ç‰©ä»¶è½‰æ›

**ä½¿ç”¨ç¯„ä¾‹**ï¼š
```python
# åŸºæœ¬ç”¨æ³•
client = CommonBrick.toGrpcClient("localhost:50051")

# å¸¶åƒæ•¸ç”¨æ³•
client = CommonBrick.toGrpcClient(
    "production-server:443",
    verbose=False
)

# ä½¿ç”¨å®¢æˆ¶ç«¯
request = CommonRequest(data={"message": "Hello"})
response = await client.run_unary(request)
```

**æ³¨æ„äº‹é …**ï¼š
- æ¯æ¬¡èª¿ç”¨æœƒå»ºç«‹æ–°çš„ gRPC é€šé“ï¼Œé©åˆçŸ­æœŸä½¿ç”¨
- é•·æœŸä½¿ç”¨å»ºè­°å¯¦ä½œé€£ç·šæ± ç®¡ç†
- è‡ªå‹•è™•ç†é€£ç·šéŒ¯èª¤å’Œé‡è©¦æ©Ÿåˆ¶

#### æ¨™æº–åŸ·è¡Œæ–¹æ³•

##### [`run_unary()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L233) - å–®æ¬¡è«‹æ±‚åŸ·è¡Œ

```python
async def run_unary(self, input_data: CommonRequest) -> CommonResponse
```

**åŠŸèƒ½**ï¼šåŸ·è¡Œå–®æ¬¡è«‹æ±‚/å›æ‡‰è™•ç†

**åƒæ•¸**ï¼š
- `input_data: CommonRequest` - è¼¸å…¥è«‹æ±‚ç‰©ä»¶

**å›å‚³**ï¼š`CommonResponse` - è™•ç†çµæœ

**ä½¿ç”¨å ´æ™¯**ï¼š
- ç°¡å–®çš„è³‡æ–™è½‰æ›
- ç‹€æ…‹æŸ¥è©¢
- é©—è­‰æ“ä½œ
- è¨ˆç®—ä»»å‹™

**ç¯„ä¾‹**ï¼š
```python
brick = CommonBrick()

@brick.unary()
async def calculator(request: CommonRequest) -> CommonResponse:
    a = request.data.get("a", 0)
    b = request.data.get("b", 0)
    operation = request.data.get("operation", "add")
    
    if operation == "add":
        result = a + b
    elif operation == "multiply":
        result = a * b
    else:
        return CommonResponse(
            error=ErrorCodes.parameter_invalid("operation")
        )
    
    return CommonResponse(
        data={"result": result},
        error=ErrorCodes.success()
    )

# ä½¿ç”¨
request = CommonRequest(data={"a": 10, "b": 5, "operation": "add"})
response = await brick.run_unary(request)
print(response.data["result"])  # 15
```

##### [`run_output_streaming()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L258) - è¼¸å‡ºä¸²æµåŸ·è¡Œ

```python
async def run_output_streaming(self, input_data: CommonRequest) -> AsyncIterator[CommonResponse]
```

**åŠŸèƒ½**ï¼šåŸ·è¡Œè¼¸å‡ºä¸²æµè™•ç†ï¼Œå¾å–®ä¸€è¼¸å…¥ç”¢ç”Ÿå¤šå€‹è¼¸å‡º

**åƒæ•¸**ï¼š
- `input_data: CommonRequest` - è¼¸å…¥è«‹æ±‚ç‰©ä»¶

**å›å‚³**ï¼š`AsyncIterator[CommonResponse]` - ç•°æ­¥å›æ‡‰è¿­ä»£å™¨

**ä½¿ç”¨å ´æ™¯**ï¼š
- å¤§å‹è³‡æ–™åˆ†é è¼¸å‡º
- å³æ™‚è³‡æ–™ä¸²æµ
- é•·æ™‚é–“è™•ç†çš„é€²åº¦å›å ±
- èŠå¤©æ©Ÿå™¨äººå›æ‡‰ç”Ÿæˆ

**ç¯„ä¾‹**ï¼š
```python
@brick.output_streaming()
async def data_paginator(request: CommonRequest) -> AsyncIterator[CommonResponse]:
    """è³‡æ–™åˆ†é ä¸²æµè¼¸å‡º"""
    page_size = request.data.get("page_size", 10)
    total_items = request.data.get("total_items", 100)
    
    for page in range(0, total_items, page_size):
        # æ¨¡æ“¬è³‡æ–™åº«æŸ¥è©¢
        await asyncio.sleep(0.1)
        
        items = [f"item_{i}" for i in range(page, min(page + page_size, total_items))]
        
        yield CommonResponse(
            data={
                "page": page // page_size + 1,
                "items": items,
                "has_more": page + page_size < total_items
            },
            error=ErrorCodes.success()
        )

# ä½¿ç”¨
request = CommonRequest(data={"page_size": 5, "total_items": 23})
async for response in brick.run_output_streaming(request):
    print(f"ç¬¬ {response.data['page']} é : {response.data['items']}")
```

##### [`run_input_streaming()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L274) - è¼¸å…¥ä¸²æµåŸ·è¡Œ

```python
async def run_input_streaming(self, input_stream: AsyncIterator[CommonRequest]) -> CommonResponse
```

**åŠŸèƒ½**ï¼šåŸ·è¡Œè¼¸å…¥ä¸²æµè™•ç†ï¼Œå¾å¤šå€‹è¼¸å…¥ç”¢ç”Ÿå–®ä¸€è¼¸å‡º

**åƒæ•¸**ï¼š
- `input_stream: AsyncIterator[CommonRequest]` - è¼¸å…¥è«‹æ±‚ä¸²æµ

**å›å‚³**ï¼š`CommonResponse` - æœ€çµ‚è™•ç†çµæœ

**ä½¿ç”¨å ´æ™¯**ï¼š
- æ‰¹æ¬¡è³‡æ–™è™•ç†
- æª”æ¡ˆä¸Šå‚³è™•ç†
- è³‡æ–™èšåˆåˆ†æ
- ä¸²æµè³‡æ–™æ”¶é›†

**ç¯„ä¾‹**ï¼š
```python
@brick.input_streaming()
async def batch_analyzer(request_stream: AsyncIterator[CommonRequest]) -> CommonResponse:
    """æ‰¹æ¬¡è³‡æ–™åˆ†æ"""
    total_count = 0
    sum_values = 0
    categories = {}
    
    async for request in request_stream:
        value = request.data.get("value", 0)
        category = request.data.get("category", "unknown")
        
        total_count += 1
        sum_values += value
        categories[category] = categories.get(category, 0) + 1
    
    if total_count == 0:
        return CommonResponse(
            error=ErrorCodes.parameter_invalid("input_stream", "æ²’æœ‰æ”¶åˆ°ä»»ä½•è³‡æ–™")
        )
    
    return CommonResponse(
        data={
            "total_count": total_count,
            "average_value": sum_values / total_count,
            "categories": categories,
            "summary": f"è™•ç†äº† {total_count} ç­†è³‡æ–™ï¼Œå¹³å‡å€¼ç‚º {sum_values/total_count:.2f}"
        },
        error=ErrorCodes.success()
    )

# ä½¿ç”¨
async def data_generator():
    data_points = [
        {"value": 10, "category": "A"},
        {"value": 20, "category": "B"},
        {"value": 15, "category": "A"},
        {"value": 25, "category": "C"}
    ]
    for point in data_points:
        yield CommonRequest(data=point)

response = await brick.run_input_streaming(data_generator())
print(response.data["summary"])
```

##### [`run_bidi_streaming()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L288) - é›™å‘ä¸²æµåŸ·è¡Œ

```python
async def run_bidi_streaming(self, input_stream: AsyncIterator[CommonRequest]) -> AsyncIterator[CommonResponse]
```

**åŠŸèƒ½**ï¼šåŸ·è¡Œé›™å‘ä¸²æµè™•ç†ï¼Œå³æ™‚è™•ç†è¼¸å…¥ä¸¦ç”¢ç”Ÿè¼¸å‡º

**åƒæ•¸**ï¼š
- `input_stream: AsyncIterator[CommonRequest]` - è¼¸å…¥è«‹æ±‚ä¸²æµ

**å›å‚³**ï¼š`AsyncIterator[CommonResponse]` - è¼¸å‡ºå›æ‡‰ä¸²æµ

**ä½¿ç”¨å ´æ™¯**ï¼š
- å³æ™‚èŠå¤©ç³»çµ±
- äº’å‹•å¼è³‡æ–™è™•ç†
- å³æ™‚ç¿»è­¯æœå‹™
- éŠæˆ²ç‹€æ…‹åŒæ­¥

**ç¯„ä¾‹**ï¼š
```python
@brick.bidi_streaming()
async def chat_processor(request_stream: AsyncIterator[CommonRequest]) -> AsyncIterator[CommonResponse]:
    """èŠå¤©è™•ç†å™¨"""
    conversation_history = []
    
    async for request in request_stream:
        message = request.data.get("message", "")
        user_id = request.data.get("user_id", "anonymous")
        
        if not message:
            yield CommonResponse(
                error=ErrorCodes.parameter_invalid("message")
            )
            continue
        
        # è¨˜éŒ„å°è©±æ­·å²
        conversation_history.append(f"{user_id}: {message}")
        
        # ç°¡å–®çš„å›æ‡‰é‚è¼¯
        if message.lower() == "history":
            response_text = "\n".join(conversation_history[-5:])  # æœ€è¿‘5æ¢
        elif message.lower() == "clear":
            conversation_history.clear()
            response_text = "å°è©±æ­·å²å·²æ¸…é™¤"
        else:
            response_text = f"æ”¶åˆ°ä¾†è‡ª {user_id} çš„è¨Šæ¯: {message}"
        
        yield CommonResponse(
            data={
                "response": response_text,
                "timestamp": asyncio.get_event_loop().time(),
                "conversation_length": len(conversation_history)
            },
            error=ErrorCodes.success()
        )

# ä½¿ç”¨
async def chat_input():
    messages = [
        {"message": "Hello", "user_id": "Alice"},
        {"message": "How are you?", "user_id": "Bob"},
        {"message": "history", "user_id": "Alice"}
    ]
    for msg in messages:
        yield CommonRequest(data=msg)
        await asyncio.sleep(1)

async for response in brick.run_bidi_streaming(chat_input()):
    print(response.data["response"])
```

##### [`run_get_service_info()`](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py#L245) - æœå‹™è³‡è¨ŠæŸ¥è©¢

```python
async def run_get_service_info(self) -> ServiceInfoResponse
```

**åŠŸèƒ½**ï¼šæŸ¥è©¢æœå‹™çš„åŸºæœ¬è³‡è¨Šå’Œèƒ½åŠ›

**å›å‚³**ï¼š`ServiceInfoResponse` - æœå‹™è³‡è¨Šç‰©ä»¶

**ä½¿ç”¨å ´æ™¯**ï¼š
- æœå‹™ç™¼ç¾
- å¥åº·æª¢æŸ¥
- èƒ½åŠ›æŸ¥è©¢
- ç‰ˆæœ¬æª¢æŸ¥

**ç¯„ä¾‹**ï¼š
```python
@brick.get_service_info()
async def service_info() -> ServiceInfoResponse:
    """æœå‹™è³‡è¨Šæä¾›"""
    return ServiceInfoResponse(
        service_name="MyAdvancedService",
        version="2.1.0",
        models=[
            ModelInfo(
                model_id="text_processor",
                version="1.0.0",
                supported_languages=["zh-TW", "zh-CN", "en-US"],
                support_streaming=True,
                description="é«˜æ•ˆèƒ½æ–‡æœ¬è™•ç†æ¨¡å‹"
            ),
            ModelInfo(
                model_id="data_analyzer",
                version="1.2.0",
                supported_languages=["universal"],
                support_streaming=False,
                description="é€šç”¨è³‡æ–™åˆ†ææ¨¡å‹"
            )
        ],
        error=ErrorCodes.success()
    )

# ä½¿ç”¨
info = await brick.run_get_service_info()
print(f"æœå‹™: {info.service_name} v{info.version}")
for model in info.models:
    print(f"  æ¨¡å‹: {model.model_id} - {model.description}")
```

### è£é£¾å™¨ç³»çµ±è©³è§£

CommonBrick æä¾›å…©å¥—è£é£¾å™¨ç³»çµ±ï¼š**å¯¦ä¾‹è£é£¾å™¨**ï¼ˆå‹•æ…‹è¨»å†Šï¼‰å’Œ**é¡åˆ¥è£é£¾å™¨**ï¼ˆéœæ…‹è¨»å†Šï¼‰ã€‚

#### å¯¦ä¾‹è£é£¾å™¨ï¼ˆæ¨è–¦ç”¨æ–¼å‹•æ…‹å ´æ™¯ï¼‰

```python
# å»ºç«‹ Brick å¯¦ä¾‹
brick = CommonBrick()

# ä½¿ç”¨å¯¦ä¾‹è£é£¾å™¨å‹•æ…‹è¨»å†Šè™•ç†å™¨
@brick.unary()
async def dynamic_handler(request: CommonRequest) -> CommonResponse:
    return CommonResponse(data={"type": "dynamic"})

@brick.output_streaming()
async def dynamic_streaming(request: CommonRequest) -> AsyncIterator[CommonResponse]:
    for i in range(3):
        yield CommonResponse(data={"count": i})
```

**å„ªé»**ï¼š
- éˆæ´»æ€§é«˜ï¼Œå¯åœ¨é‹è¡Œæ™‚å‹•æ…‹è¨»å†Š
- é©åˆæ’ä»¶ç³»çµ±å’Œå‹•æ…‹é…ç½®
- å¯ä»¥æœ‰æ¢ä»¶åœ°è¨»å†Šè™•ç†å™¨

**ç¼ºé»**ï¼š
- éœ€è¦å…ˆå»ºç«‹å¯¦ä¾‹
- ä¸é©åˆé¡åˆ¥ç¹¼æ‰¿å ´æ™¯

#### é¡åˆ¥è£é£¾å™¨ï¼ˆæ¨è–¦ç”¨æ–¼ç¹¼æ‰¿å ´æ™¯ï¼‰

```python
from llmbrick.core.brick import unary_handler, output_streaming_handler

class MyBrick(CommonBrick):
    @unary_handler
    async def static_handler(self, request: CommonRequest) -> CommonResponse:
        return CommonResponse(data={"type": "static"})
    
    @output_streaming_handler
    async def static_streaming(self, request: CommonRequest) -> AsyncIterator[CommonResponse]:
        for i in range(3):
            yield CommonResponse(data={"count": i})
```

**å„ªé»**ï¼š
- æ¸…æ™°çš„é¡åˆ¥çµæ§‹
- è‡ªå‹•è¨»å†Šï¼Œç„¡éœ€é¡å¤–æ­¥é©Ÿ
- é©åˆç‰©ä»¶å°å‘è¨­è¨ˆ
- æ”¯æ´ç¹¼æ‰¿å’Œå¤šå‹

**ç¼ºé»**ï¼š
- éœæ…‹è¨»å†Šï¼Œé‹è¡Œæ™‚ç„¡æ³•ä¿®æ”¹
- æ¯å€‹é¡åˆ¥åªèƒ½æœ‰ä¸€å€‹åŒé¡å‹è™•ç†å™¨

---

## æ•ˆèƒ½å„ªåŒ–èˆ‡æœ€ä½³å¯¦è¸

### 1. ç•°æ­¥è™•ç†å„ªåŒ–

#### ä¸¦ç™¼æ§åˆ¶

```python
import asyncio
from asyncio import Semaphore
from typing import List, AsyncIterator
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse

class HighPerformanceBrick(CommonBrick):
    """é«˜æ•ˆèƒ½ CommonBrick å¯¦ä½œ"""
    
    def __init__(self, 
                 max_concurrent_requests: int = 100,
                 request_timeout: float = 30.0,
                 **kwargs):
        super().__init__(**kwargs)
        
        # ä¸¦ç™¼æ§åˆ¶
        self.semaphore = Semaphore(max_concurrent_requests)
        self.request_timeout = request_timeout
        
        # æ•ˆèƒ½æŒ‡æ¨™
        self.performance_stats = {
            "total_requests": 0,
            "concurrent_requests": 0,
            "max_concurrent": 0,
            "average_response_time": 0.0,
            "total_response_time": 0.0
        }
    
    async def _with_concurrency_control(self, coro):
        """ä¸¦ç™¼æ§åˆ¶åŒ…è£å™¨"""
        async with self.semaphore:
            self.performance_stats["concurrent_requests"] += 1
            self.performance_stats["max_concurrent"] = max(
                self.performance_stats["max_

concurrent"],
                self.performance_stats["concurrent_requests"]
            )
            
            start_time = asyncio.get_event_loop().time()
            
            try:
                result = await asyncio.wait_for(coro, timeout=self.request_timeout)
                
                # æ›´æ–°æ•ˆèƒ½çµ±è¨ˆ
                response_time = asyncio.get_event_loop().time() - start_time
                self.performance_stats["total_requests"] += 1
                self.performance_stats["total_response_time"] += response_time
                self.performance_stats["average_response_time"] = (
                    self.performance_stats["total_response_time"] / 
                    self.performance_stats["total_requests"]
                )
                
                return result
                
            finally:
                self.performance_stats["concurrent_requests"] -= 1
    
    @unary_handler
    async def high_performance_handler(self, request: CommonRequest) -> CommonResponse:
        """é«˜æ•ˆèƒ½è™•ç†å™¨"""
        
        async def process_request():
            # æ¨¡æ“¬è™•ç†é‚è¼¯
            data = request.data
            operation = data.get("operation", "default")
            
            if operation == "cpu_intensive":
                # CPU å¯†é›†å‹ä»»å‹™
                result = await self._cpu_intensive_task(data)
            elif operation == "io_intensive":
                # I/O å¯†é›†å‹ä»»å‹™
                result = await self._io_intensive_task(data)
            else:
                # ä¸€èˆ¬è™•ç†
                result = {"processed": True, "data": data}
            
            return CommonResponse(
                data=result,
                error=ErrorCodes.success()
            )
        
        return await self._with_concurrency_control(process_request())
    
    async def _cpu_intensive_task(self, data: dict) -> dict:
        """CPU å¯†é›†å‹ä»»å‹™ï¼ˆåœ¨åŸ·è¡Œå™¨ä¸­é‹è¡Œï¼‰"""
        import concurrent.futures
        
        def cpu_work():
            # æ¨¡æ“¬ CPU å¯†é›†å‹è¨ˆç®—
            result = sum(i * i for i in range(10000))
            return {"computation_result": result, "input": data}
        
        # åœ¨ç·šç¨‹æ± ä¸­åŸ·è¡Œ CPU å¯†é›†å‹ä»»å‹™
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            result = await loop.run_in_executor(executor, cpu_work)
        
        return result
    
    async def _io_intensive_task(self, data: dict) -> dict:
        """I/O å¯†é›†å‹ä»»å‹™"""
        # æ¨¡æ“¬ç•°æ­¥ I/O æ“ä½œ
        await asyncio.sleep(0.1)
        return {"io_result": "completed", "input": data}
    
    def get_performance_stats(self) -> dict:
        """ç²å–æ•ˆèƒ½çµ±è¨ˆ"""
        return self.performance_stats.copy()

# æ•ˆèƒ½æ¸¬è©¦ç¯„ä¾‹
async def performance_test():
    """æ•ˆèƒ½æ¸¬è©¦"""
    
    brick = HighPerformanceBrick(
        max_concurrent_requests=50,
        request_timeout=10.0
    )
    
    print("ğŸš€ é–‹å§‹æ•ˆèƒ½æ¸¬è©¦...")
    
    # å»ºç«‹æ¸¬è©¦è«‹æ±‚
    requests = [
        CommonRequest(data={"operation": "cpu_intensive", "id": i})
        for i in range(20)
    ] + [
        CommonRequest(data={"operation": "io_intensive", "id": i})
        for i in range(30)
    ]
    
    # ä¸¦ç™¼åŸ·è¡Œè«‹æ±‚
    start_time = asyncio.get_event_loop().time()
    
    tasks = [brick.run_unary(req) for req in requests]
    responses = await asyncio.gather(*tasks, return_exceptions=True)
    
    end_time = asyncio.get_event_loop().time()
    
    # åˆ†æçµæœ
    successful = sum(1 for r in responses if isinstance(r, CommonResponse) and r.error.code == 200)
    failed = len(responses) - successful
    total_time = end_time - start_time
    
    print(f"ğŸ“Š æ•ˆèƒ½æ¸¬è©¦çµæœ:")
    print(f"   ç¸½è«‹æ±‚æ•¸: {len(requests)}")
    print(f"   æˆåŠŸ: {successful}")
    print(f"   å¤±æ•—: {failed}")
    print(f"   ç¸½æ™‚é–“: {total_time:.2f}s")
    print(f"   å¹³å‡ QPS: {len(requests) / total_time:.2f}")
    
    # é¡¯ç¤ºå…§éƒ¨çµ±è¨ˆ
    stats = brick.get_performance_stats()
    print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {stats['average_response_time']:.3f}s")
    print(f"   æœ€å¤§ä¸¦ç™¼æ•¸: {stats['max_concurrent']}")

asyncio.run(performance_test())
```

### 2. å¿«å–ç­–ç•¥å„ªåŒ–

```python
import asyncio
import hashlib
import json
from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Tuple
from dataclasses import dataclass
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse
from llmbrick.core.error_codes import ErrorCodes

@dataclass
class CacheConfig:
    """å¿«å–é…ç½®"""
    max_size: int = 1000
    ttl_seconds: int = 3600
    enable_lru: bool = True
    enable_compression: bool = False
    hit_rate_threshold: float = 0.7

class SmartCache:
    """æ™ºèƒ½å¿«å–ç³»çµ±"""
    
    def __init__(self, config: CacheConfig):
        self.config = config
        self.cache: Dict[str, Tuple[Any, datetime, int]] = {}  # value, timestamp, access_count
        self.access_order: List[str] = []  # LRU é †åº
        self.stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0,
            "size": 0
        }
    
    def _generate_key(self, data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¿«å–éµå€¼"""
        serialized = json.dumps(data, sort_keys=True)
        return hashlib.md5(serialized.encode()).hexdigest()
    
    def _is_expired(self, timestamp: datetime) -> bool:
        """æª¢æŸ¥æ˜¯å¦éæœŸ"""
        return datetime.now() - timestamp > timedelta(seconds=self.config.ttl_seconds)
    
    def _evict_lru(self):
        """LRU æ·˜æ±°"""
        if not self.access_order:
            return
        
        oldest_key = self.access_order.pop(0)
        if oldest_key in self.cache:
            del self.cache[oldest_key]
            self.stats["evictions"] += 1
    
    def _update_access_order(self, key: str):
        """æ›´æ–°è¨ªå•é †åº"""
        if self.config.enable_lru:
            if key in self.access_order:
                self.access_order.remove(key)
            self.access_order.append(key)
    
    def get(self, data: Dict[str, Any]) -> Optional[Any]:
        """ç²å–å¿«å–"""
        key = self._generate_key(data)
        
        if key not in self.cache:
            self.stats["misses"] += 1
            return None
        
        value, timestamp, access_count = self.cache[key]
        
        # æª¢æŸ¥éæœŸ
        if self._is_expired(timestamp):
            del self.cache[key]
            if key in self.access_order:
                self.access_order.remove(key)
            self.stats["misses"] += 1
            return None
        
        # æ›´æ–°è¨ªå•è¨˜éŒ„
        self.cache[key] = (value, timestamp, access_count + 1)
        self._update_access_order(key)
        self.stats["hits"] += 1
        
        return value
    
    def set(self, data: Dict[str, Any], value: Any):
        """è¨­å®šå¿«å–"""
        key = self._generate_key(data)
        
        # æª¢æŸ¥å®¹é‡é™åˆ¶
        if len(self.cache) >= self.config.max_size and key not in self.cache:
            self._evict_lru()
        
        # è¨­å®šå¿«å–
        self.cache[key] = (value, datetime.now(), 0)
        self._update_access_order(key)
        self.stats["size"] = len(self.cache)
    
    def get_hit_rate(self) -> float:
        """ç²å–å‘½ä¸­ç‡"""
        total = self.stats["hits"] + self.stats["misses"]
        return self.stats["hits"] / total if total > 0 else 0.0
    
    def clear_expired(self):
        """æ¸…ç†éæœŸé …ç›®"""
        expired_keys = []
        for key, (_, timestamp, _) in self.cache.items():
            if self._is_expired(timestamp):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
            if key in self.access_order:
                self.access_order.remove(key)
        
        self.stats["size"] = len(self.cache)
        return len(expired_keys)

class CacheOptimizedBrick(CommonBrick):
    """å¿«å–å„ªåŒ–çš„ Brick"""
    
    def __init__(self, cache_config: CacheConfig = None, **kwargs):
        super().__init__(**kwargs)
        
        self.cache_config = cache_config or CacheConfig()
        self.cache = SmartCache(self.cache_config)
        
        # å•Ÿå‹•å¿«å–ç¶­è­·ä»»å‹™
        asyncio.create_task(self._cache_maintenance())
    
    async def _cache_maintenance(self):
        """å¿«å–ç¶­è­·ä»»å‹™"""
        while True:
            try:
                await asyncio.sleep(300)  # æ¯5åˆ†é˜åŸ·è¡Œä¸€æ¬¡
                
                # æ¸…ç†éæœŸé …ç›®
                expired_count = self.cache.clear_expired()
                
                # æª¢æŸ¥å‘½ä¸­ç‡
                hit_rate = self.cache.get_hit_rate()
                
                print(f"ğŸ§¹ å¿«å–ç¶­è­·: æ¸…ç† {expired_count} å€‹éæœŸé …ç›®, "
                      f"å‘½ä¸­ç‡: {hit_rate:.2%}, "
                      f"å¤§å°: {self.cache.stats['size']}")
                
                # å¦‚æœå‘½ä¸­ç‡éä½ï¼Œèª¿æ•´ç­–ç•¥
                if hit_rate < self.cache_config.hit_rate_threshold:
                    print(f"âš ï¸  å¿«å–å‘½ä¸­ç‡éä½ ({hit_rate:.2%}), è€ƒæ…®èª¿æ•´å¿«å–ç­–ç•¥")
                
            except Exception as e:
                print(f"å¿«å–ç¶­è­·éŒ¯èª¤: {e}")
    
    @unary_handler
    async def cached_handler(self, request: CommonRequest) -> CommonResponse:
        """å¸¶å¿«å–çš„è™•ç†å™¨"""
        
        # å˜—è©¦å¾å¿«å–ç²å–
        cached_result = self.cache.get(request.data)
        if cached_result:
            return CommonResponse(
                data={**cached_result, "from_cache": True},
                error=ErrorCodes.success()
            )
        
        # åŸ·è¡Œå¯¦éš›è™•ç†
        try:
            result = await self._process_data(request.data)
            
            # å­˜å…¥å¿«å–
            self.cache.set(request.data, result)
            
            return CommonResponse(
                data={**result, "from_cache": False},
                error=ErrorCodes.success()
            )
            
        except Exception as e:
            return CommonResponse(
                error=ErrorCodes.internal_error("è™•ç†å¤±æ•—", str(e))
            )
    
    async def _process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¦éš›è³‡æ–™è™•ç†é‚è¼¯"""
        # æ¨¡æ“¬è¤‡é›œè™•ç†
        await asyncio.sleep(0.5)
        
        operation = data.get("operation", "default")
        
        if operation == "calculate":
            numbers = data.get("numbers", [])
            result = {
                "sum": sum(numbers),
                "average": sum(numbers) / len(numbers) if numbers else 0,
                "count": len(numbers)
            }
        elif operation == "transform":
            text = data.get("text", "")
            result = {
                "original": text,
                "uppercase": text.upper(),
                "length": len(text),
                "words": len(text.split())
            }
        else:
            result = {"processed": True, "operation": operation}
        
        return result
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ç²å–å¿«å–çµ±è¨ˆ"""
        stats = self.cache.stats.copy()
        stats["hit_rate"] = self.cache.get_hit_rate()
        stats["config"] = {
            "max_size": self.cache_config.max_size,
            "ttl_seconds": self.cache_config.ttl_seconds,
            "enable_lru": self.cache_config.enable_lru
        }
        return stats

# å¿«å–æ•ˆèƒ½æ¸¬è©¦
async def cache_performance_test():
    """å¿«å–æ•ˆèƒ½æ¸¬è©¦"""
    
    config = CacheConfig(
        max_size=100,
        ttl_seconds=60,
        enable_lru=True
    )
    
    brick = CacheOptimizedBrick(cache_config=config)
    
    print("ğŸ§ª å¿«å–æ•ˆèƒ½æ¸¬è©¦é–‹å§‹...")
    
    # æ¸¬è©¦è³‡æ–™
    test_requests = [
        CommonRequest(data={"operation": "calculate", "numbers": [1, 2, 3, 4, 5]}),
        CommonRequest(data={"operation": "transform", "text": "Hello World"}),
        CommonRequest(data={"operation": "calculate", "numbers": [10, 20, 30]}),
        # é‡è¤‡è«‹æ±‚æ¸¬è©¦å¿«å–å‘½ä¸­
        CommonRequest(data={"operation": "calculate", "numbers": [1, 2, 3, 4, 5]}),
        CommonRequest(data={"operation": "transform", "text": "Hello World"}),
    ]
    
    # åŸ·è¡Œæ¸¬è©¦
    for i, request in enumerate(test_requests):
        start_time = asyncio.get_event_loop().time()
        response = await brick.run_unary(request)
        end_time = asyncio.get_event_loop().time()
        
        if response.error.code == 200:
            from_cache = response.data.get("from_cache", False)
            print(f"è«‹æ±‚ {i+1}: {'å¿«å–å‘½ä¸­' if from_cache else 'å¯¦éš›è™•ç†'} "
                  f"({end_time - start_time:.3f}s)")
    
    # é¡¯ç¤ºå¿«å–çµ±è¨ˆ
    stats = brick.get_cache_stats()
    print(f"\nğŸ“Š å¿«å–çµ±è¨ˆ:")
    print(f"   å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
    print(f"   å‘½ä¸­æ¬¡æ•¸: {stats['hits']}")
    print(f"   æœªå‘½ä¸­æ¬¡æ•¸: {stats['misses']}")
    print(f"   å¿«å–å¤§å°: {stats['size']}")

asyncio.run(cache_performance_test())
```

### 3. æ‰¹æ¬¡è™•ç†å„ªåŒ–

```python
import asyncio
from typing import List, AsyncIterator, Callable, Any
from dataclasses import dataclass
from llmbrick.bricks.common.common import CommonBrick
from llmbrick.protocols.models.bricks.common_types import CommonRequest, CommonResponse
from llmbrick.core.error_codes import ErrorCodes

@dataclass
class BatchConfig:
    """æ‰¹æ¬¡è™•ç†é…ç½®"""
    batch_size: int = 10
    max_wait_time: float = 1.0
    max_queue_size: int = 1000
    enable_adaptive_batching: bool = True

class BatchProcessor:
    """æ‰¹æ¬¡è™•ç†å™¨"""
    
    def __init__(self, 
                 config: BatchConfig,
                 process_func: Callable[[List[Any]], List[Any]]):
        self.config = config
        self.process_func = process_func
        self.queue: List[Tuple[Any, asyncio.Future]] = []
        self.processing = False
        
        # å•Ÿå‹•æ‰¹æ¬¡è™•ç†ä»»å‹™
        asyncio.create_task(self._batch_processing_loop())
    
    async def add_to_batch(self, item: Any) -> Any:
        """æ·»åŠ é …ç›®åˆ°æ‰¹æ¬¡"""
        if len(self.queue) >= self.config.max_queue_size:
            raise Exception(f"æ‰¹æ¬¡ä½‡åˆ—å·²æ»¿: {self.config.max_queue_size}")
        
        future = asyncio.Future()
        self.queue.append((item, future))
        
        # å¦‚æœé”åˆ°æ‰¹æ¬¡å¤§å°ï¼Œç«‹å³è™•ç†
        if len(self.queue) >= self.config.batch_size:
            asyncio.create_task(self._process_batch())
        
        return await future
    
    async def _batch_processing_loop(self):
        """æ‰¹æ¬¡è™•ç†å¾ªç’°"""
        while True:
            try:
                await asyncio.sleep(self.config.max_wait_time)
                
                if self.queue and not self.processing:
                    await self._process_batch()
                    
            except Exception as e:
                print(f"æ‰¹æ¬¡è™•ç†å¾ªç’°éŒ¯èª¤: {e}")
    
    async def _process_batch(self):
        """è™•ç†æ‰¹æ¬¡"""
        if self.processing or not self.queue:
            return
        
        self.processing = True
        
        try:
            # å–å‡ºæ‰¹æ¬¡é …ç›®
            batch_size = min(len(self.queue), self.config.batch_size)
            batch_items = self.queue[:batch_size]
            self.queue = self.queue[batch_size:]
            
            # åˆ†é›¢è³‡æ–™å’Œ Future
            items = [item for item, _ in batch_items]
            futures = [future for _, future in batch_items]
            
            # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
            results = await self.process_func(items)
            
            # è¨­å®šçµæœ
            for future, result in zip(futures, results):
                if not future.done():
                    future.set_result(result)
                    
        except Exception as e:
            # è¨­å®šéŒ¯èª¤
            for _, future in batch_items:
                if not future.done():
                    future.set_exception(e)
        finally:
            self.processing = False

class BatchOptimizedBrick(CommonBrick):
    """æ‰¹æ¬¡å„ªåŒ–çš„ Brick"""
    
    def __init__(self, batch_config: BatchConfig = None, **kwargs):
        super().__init__(**kwargs)
        
        self.batch_config = batch_config or BatchConfig()
        
        # å»ºç«‹ä¸åŒé¡å‹çš„æ‰¹æ¬¡è™•ç†å™¨
        self.text_processor = BatchProcessor(
            self.batch_config,
            self._batch_process_text
        )
        
        self.number_processor = BatchProcessor(
            self.batch_config,
            self._batch_process_numbers
        )
    
    @unary_handler
    async def batch_optimized_handler(self, request: CommonRequest) -> CommonResponse:
        """æ‰¹æ¬¡å„ªåŒ–çš„è™•ç†å™¨"""
        
        try:
            data_type = request.data.get("type", "text")
            data = request.data.get("data")
            
            if data_type == "text":
                result = await self.text_processor.add_to_batch(data)
            elif data_type == "number":
                result = await self.number_processor.add_to_batch(data)
            else:
                return CommonResponse(
                    error=ErrorCodes.parameter_invalid("type", f"ä¸æ”¯æ´çš„è³‡æ–™é¡å‹: {data_type}")
                )
            
            return CommonResponse(
                data={"result": result, "processed_in_batch": True},
                error=ErrorCodes.success()
            )
            
        except Exception as e:
            return CommonResponse(
                error=ErrorCodes.internal_error("æ‰¹æ¬¡è™•ç†å¤±æ•—", str(e))
            )
    
    async def _batch_process_text(self, texts: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è™•ç†æ–‡æœ¬"""
        print(f"ğŸ“¦ æ‰¹æ¬¡è™•ç† {len(texts)} å€‹æ–‡æœ¬")
        
        # æ¨¡æ“¬æ‰¹æ¬¡è™•ç†ï¼ˆæ¯”å–®å€‹è™•ç†æ›´é«˜æ•ˆï¼‰
        await asyncio.sleep(0.1)  # æ‰¹æ¬¡è™•ç†æ™‚é–“
        
        results = []
        for text in texts:
            results.append({
                "original": text,
                "length": len(text),
                "uppercase": text.upper(),
                "word_count": len(text.split())
            })
        
        return results
    
    async def _batch_process_numbers(self, numbers: List[float]) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è™•ç†æ•¸å­—"""
        print(f"ğŸ“¦ æ‰¹æ¬¡è™•ç† {len(numbers)} å€‹æ•¸å­—")
        
        # æ¨¡æ“¬æ‰¹æ¬¡è™•ç†
        await asyncio.sleep(0.05)
        
        # æ‰¹æ¬¡çµ±è¨ˆè¨ˆç®—
        total = sum(numbers)
        average = total / len(numbers) if numbers else 0
        
        results = []
        for num in numbers:
            results.append({
                "original": num,
                "squared": num ** 2,
                "percentage_of_total": (num / total * 100) if total != 0 else 0,
                "deviation_from_avg": num - average
            })
        
        return results

# æ‰¹æ¬¡è™•ç†æ¸¬è©¦
async def batch_processing_test():
    """æ‰¹æ¬¡è™•ç†æ¸¬è©¦"""
    
    config = BatchConfig(
        batch_size=5,
        max_wait_time=0.5,
        max_queue_size=100
    )
    
    brick = BatchOptimizedBrick(batch_config=config)
    
    print("ğŸš€ æ‰¹æ¬¡è™•ç†æ¸¬è©¦é–‹å§‹...")
    
    # å»ºç«‹æ¸¬è©¦è«‹æ±‚
    text_requests = [
        CommonRequest(data={"type": "text", "data": f"æ¸¬è©¦æ–‡æœ¬ {i}"})
        for i in range(12)
    ]
    
    number_requests = [
        CommonRequest(data={"type": "number", "data": float(i * 10)})
        for i in range(8)
    ]
    
    # æ··åˆè«‹æ±‚æ¸¬è©¦
    all_requests = text_requests + number_requests
    
    # ä¸¦ç™¼ç™¼é€è«‹æ±‚
    start_time = asyncio.get_event_loop().time()
    
    tasks = [brick.run_unary(req) for req in all_requests]
    responses = await asyncio.gather(*tasks)
    
    end_time = asyncio.get_event_loop().time()
    
    # åˆ†æçµæœ
    successful = sum(1 for r in responses if r.error.code == 200)
    
    print(f"ğŸ“Š æ‰¹æ¬¡è™•ç†çµæœ:")
    print(f"   ç¸½è«‹æ±‚æ•¸: {len(all_requests)}")
    print(f"   æˆåŠŸè™•ç†: {successful}")
    print(f"   ç¸½æ™‚é–“: {end_time - start_time:.2f}s")
    print(f"   å¹³å‡æ¯è«‹æ±‚: {(end_time - start_time) / len(all_requests):.3f}s")

asyncio.run(batch_processing_test())
```

---

## FAQ / é€²éšå•ç­”

### Q1: CommonBrick èˆ‡å…¶ä»– Brick é¡å‹çš„é—œä¿‚æ˜¯ä»€éº¼ï¼Ÿ

**A**: CommonBrick æ˜¯æ•´å€‹ LLMBrick æ¡†æ¶çš„åŸºç¤é¡åˆ¥ï¼Œå…¶ä»–æ‰€æœ‰å°ˆç”¨ Brick éƒ½ç¹¼æ‰¿è‡ª CommonBrickï¼š

```python
# ç¹¼æ‰¿é—œä¿‚ç¤ºä¾‹
from llmbrick.bricks.common.common import CommonBrick

class LLMBrick(CommonBrick):
    """èªè¨€æ¨¡å‹ Brickï¼Œç¹¼æ‰¿ CommonBrick çš„æ‰€æœ‰åŠŸèƒ½"""
    pass

class GuardBrick(CommonBrick):
    """å®‰å…¨é˜²è­· Brickï¼Œç¹¼æ‰¿ CommonBrick çš„æ‰€æœ‰åŠŸèƒ½"""
    pass

# é€™æ„å‘³è‘—æ‰€æœ‰ Brick éƒ½å…·å‚™ï¼š
# 1. ç›¸åŒçš„é€šè¨Šå”å®šï¼ˆgRPCï¼‰
# 2. çµ±ä¸€çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
# 3. æ¨™æº–çš„è³‡æ–™æ¨¡å‹ï¼ˆCommonRequest/CommonResponseï¼‰
# 4. äº”ç¨®é€šè¨Šæ¨¡å¼æ”¯æ´
```

**å„ªå‹¢**ï¼š
- **çµ±ä¸€ä»‹é¢**ï¼šæ‰€æœ‰ Brick éƒ½å¯ä»¥äº’æ›ä½¿ç”¨
- **çµ„åˆèƒ½åŠ›**ï¼šå¯ä»¥è¼•é¬†çµ„åˆä¸åŒé¡å‹çš„ Brick
- **æ“´å±•æ€§**ï¼šæ–°çš„ Brick é¡å‹å¯ä»¥å¿«é€Ÿé–‹ç™¼

---

## åƒè€ƒè³‡æºèˆ‡å»¶ä¼¸é–±è®€

### å®˜æ–¹æ–‡ä»¶

- [LLMBrick æ¡†æ¶ä»‹ç´¹](../../intro.md) - æ¡†æ¶æ•´é«”æ¦‚è¿°
- [gRPC Server ä½¿ç”¨æŒ‡å—](../servers/grpc_server_guide.md) - gRPC æœå‹™å™¨è©³ç´°é…ç½®
- [BaseBrick API æ–‡ä»¶](https://github.com/JiHungLin/llmbrick/blob/main/llmbrick/core/brick.py) - åŸºç¤é¡åˆ¥åƒè€ƒ

### å¤–éƒ¨è³‡æº

- [Protocol Buffer å®˜æ–¹æ–‡ä»¶](https://developers.google.com/protocol-buffers) - Protocol Buffer èªæ³•å’Œæœ€ä½³å¯¦è¸
- [gRPC Python å®˜æ–¹æ–‡ä»¶](https://grpc.io/docs/languages/python/) - gRPC Python å¯¦ä½œæŒ‡å—
- [asyncio å®˜æ–¹æ–‡ä»¶](https://docs.python.org/3/library/asyncio.html) - Python ç•°æ­¥ç¨‹å¼è¨­è¨ˆ

### ç¤¾ç¾¤è³‡æº

- [GitHub ç¯„ä¾‹ç¨‹å¼ç¢¼](https://github.com/JiHungLin/llmbrick/tree/main/examples/common_brick_define) - å®Œæ•´ç¯„ä¾‹ç¨‹å¼ç¢¼
- [å•é¡Œå›å ±](https://github.com/JiHungLin/llmbrick/issues) - å›å ± Bug æˆ–åŠŸèƒ½è«‹æ±‚

---

CommonBrick ä¸åƒ…æ˜¯ä¸€å€‹æŠ€è¡“çµ„ä»¶ï¼Œæ›´æ˜¯æ§‹å»ºå¯æ“´å±•ã€å¯ç¶­è­· AI æ‡‰ç”¨çš„åŸºçŸ³ã€‚æŒæ¡å…¶ä½¿ç”¨æ–¹æ³•å°æ–¼é–‹ç™¼é«˜å“è³ªçš„ LLM æ‡‰ç”¨è‡³é—œé‡è¦ã€‚

*æœ¬æŒ‡å—æŒçºŒæ›´æ–°ä¸­ï¼Œå¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿åƒèˆ‡ç¤¾ç¾¤è¨è«–ï¼*
